获取全部池子的完整流程：

1. **准备工作和初始化**:

```rust
// 创建缓存目录
match create_dir_all("cache") {
    _ => {}
}
// 设置缓存文件路径
let cache_file = "cache/.cached-pools.csv";
let file_path = Path::new(cache_file);
let file_exists = file_path.exists();

// 创建文件句柄，设置读写权限
let file_handle = OpenOptions::new()
    .write(true)
    .read(true)
    .create(true)
    .open(file_path)
    .unwrap();

// 创建 CSV writer
let mut writer = csv::Writer::from_writer(file_handle);
let mut pools: Vec<Pool> = Vec::new();
```

2. **处理已有数据**:

```rust
if file_exists {
    // 从缓存文件读取已有数据
    let mut reader = csv::Reader::from_path(file_path)?;
    for row in reader.records() {
        let row = row.unwrap();
        let pool = Pool::from(row);
        match pool.version {
            DexVariant::UniswapV2 => v2_pool_cnt += 1,
        }
        pools.push(pool);
    }
} else {
    // 新文件，写入表头
    writer.write_record(&[
        "id", "address", "version", "token0", "token1",
        "fee", "block_number", "timestamp",
    ])?;
}
```

3. **建立链接和准备事件监听**:

```rust
// 连接到以太坊节点
let ws = Ws::connect(wss_url).await?;
let ws_provider = Arc::new(Provider::new(ws));

// 准备事件定义和签名
let pair_create_event = "PairCreated(address,address,address,unit256)";
let abi = parse_abi(&[&format!("event {}", pair_create_event)]).unwrap();
let pair_created_signature = abi.event("PairCreated").unwrap().signature();
```

4. **确定区块范围**:

```rust
// 确定起始ID和区块
let mut id = if pools.len() > 0 {
    pools.last().as_ref().unwrap().id as i64
} else {
    -1
};
let last_id = id as i64;

// 确定起始区块
let from_block = if id != -1 {
    pools.last().as_ref().unwrap().block_number
} else {
    from_block
};
// 获取最新区块
let to_block = ws_provider.get_block_number().await.unwrap().as_u64();
```

5. **划分区块范围**:

```rust
let mut blocks_processed = 0;
let mut block_range = Vec::new();
loop {
    let start_idx = from_block + blocks_processed;
    let mut end_idx = start_idx + chunk - 1;
    if end_idx > to_block {
        end_idx = to_block;
        block_range.push((start_idx, end_idx));
        break;
    }
    block_range.push((start_idx, end_idx));
}
```

6. **获取事件数据**:

```rust
// 在 load_uniswap_v2_pool 函数中
let event_filter = Filter::new()
    .from_block(U64::from(from_block))
    .to_block(U64::from(to_block))
    .event(event);
let logs = provider.get_logs(&event_filter).await?;

// 处理每个日志
for log in logs {
    // 检查事件签名
    let topic = log.topics[0];
    if topic != signature {
        continue;
    }

    // 获取时间戳（使用缓存优化）
    let timestamp = if !timestamp_map.contains_key(&block_number) {
        let block = provider.get_block(block_number).await.unwrap().unwrap();
        let timestamp = block.timestamp.as_u64();
        timestamp_map.insert(block_number, timestamp);
        timestamp
    } else {
        *timestamp_map.get(&block_number).unwrap()
    };

    // 解析token地址
    let token0 = H160::from(log.topics[1]);
    let token1 = H160::from(log.topics[2]);

    // 解析pair地址
    if let Ok(input) = ethers::abi::decode(&[ParamType::Address, ParamType::Uint(256)], &log.data) {
        let pair = input[0].to_owned().into_address().unwrap();
        // 创建池子数据
        let pool_data = Pool {
            id: -1,  // 临时ID
            address: pair,
            version: DexVariant::UniswapV2,
            token0, token1,
            fee: 300,
            block_number: block_number.as_u64(),
            timestamp,
        };
        pools.push(pool_data);
    }
}
```

7. **处理新数据并保存**:

```rust
// 按区块号排序
pools.sort_by_key(|p| p.block_number);

// 分配新ID并保存
let mut added = 0;
for pool in pools.iter_mut() {
    if pool.id == -1 {
        id += 1;
        pool.id = id;
    }
    if (pool.id as i64) > last_id {
        writer.serialize(pool.cache_row())?;
        added += 1;
    }
}

// 确保数据写入磁盘
writer.flush()?;
```

核心优化点：

1. 使用时间戳缓存减少区块请求
2. 批量处理区块范围
3. 只对新数据进行序列化写入
4. 使用缓冲写入提高性能
5. 保持 ID 的连续性和唯一性

这个实现确保了：

- 数据的连续性（不会遗漏区块）
- 数据的唯一性（不会重复记录）
- 性能优化（缓存和批处理）
- 数据持久化（CSV 缓存）
